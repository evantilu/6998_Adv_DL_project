{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold CV with 3-layer CNN max pooling on SR images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and env settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.min_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables/parameters used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./ckpt/reg_lr005/\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "SR_img_path = '../../data/SR_img/'\n",
    "\n",
    "num_classes = 5\n",
    "lr = 0.005\n",
    "epochs = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2911,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''read label'''\n",
    "\n",
    "df = pd.read_csv('../../data/images/label_5_cls.csv')\n",
    "df.head()\n",
    "\n",
    "labels = df['SalePrice']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  5\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "'''one-hot encode the labels'''\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "# print(list(integer_encoded))\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "labels = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print('Number of classes: ', len(labels[0]))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2911, 72, 72, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''load SR images'''\n",
    "images_arr = []\n",
    "\n",
    "for i in range(1, len(labels)+1):\n",
    "# for i in range(1, 10):\n",
    "    img = plt.imread(os.path.join(SR_img_path, 'SR_img_{}.png'.format(i)))\n",
    "    images_arr.append(img)\n",
    "\n",
    "images_arr = np.array(images_arr, dtype='float32')\n",
    "images_arr.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test splitting\n",
    "- hold out 15% for testing\n",
    "- use 85% to train model with K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_samples = images_arr.shape[0] \n",
    "test_ratio = 0.15\n",
    "test_samples = int(test_ratio * images_arr.shape[0])\n",
    "\n",
    "train_examples = images_arr[:-1*test_samples]\n",
    "test_examples = images_arr[-1*test_samples:]\n",
    "train_labels = labels[:-1*test_samples]\n",
    "test_labels = labels[-1*test_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (2475, 72, 72, 3)\n",
      "test:  (436, 72, 72, 3)\n",
      "train label:  (2475, 5)\n",
      "test label:  (436, 5)\n"
     ]
    }
   ],
   "source": [
    "print('train: ', train_examples.shape)\n",
    "print('test: ', test_examples.shape)\n",
    "print('train label: ', train_labels.shape)\n",
    "print('test label: ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "def create_model(num_classes=5, lr=0.005):\n",
    "\n",
    "\t# Working\n",
    "\twith tf.device('/cpu:0'):\n",
    "\t\tdata_augmentation = tf.keras.Sequential([ \n",
    "\t\t\ttf.keras.layers.RandomFlip(\"horizontal\", input_shape=(72, 72, 3)),\n",
    "\t  \t\ttf.keras.layers.RandomRotation(0.1),\n",
    "\t\t    tf.keras.layers.RandomZoom(0.1)\n",
    "\t\t\t])\n",
    "\n",
    "\n",
    "\tmodel = tf.keras.Sequential([\n",
    "\t\t# data_augmentation,\n",
    "\t  \t# tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "\t  \ttf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(72, 72, 3)),\n",
    "\t\ttf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\t\ttf.keras.layers.Dropout(0.1),\n",
    "\t\ttf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "\t  \ttf.keras.layers.MaxPooling2D((2,2)),\n",
    "\t\ttf.keras.layers.Dropout(0.1),\n",
    "\t  \ttf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "\t  \ttf.keras.layers.MaxPooling2D(),\n",
    "\t\ttf.keras.layers.Dropout(0.1),\n",
    "\t\ttf.keras.layers.Flatten(),\n",
    "\t\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\t\ttf.keras.layers.Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "\t])\n",
    "\n",
    "\t# opt = tf.keras.optimizers.SGD(lr=0.005, momentum=0.9)\n",
    "\topt = tf.keras.optimizers.Adam(lr=lr)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:46:16.306437: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-30 22:46:16.306594: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/evantilu/miniforge3/envs/6998_DL_tf/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:46:18.350847: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-30 22:46:18.628122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - ETA: 0s - loss: 1.2582 - accuracy: 0.4473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:46:21.135515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 3s 23ms/step - loss: 1.2582 - accuracy: 0.4473 - val_loss: 0.9388 - val_accuracy: 0.5872\n",
      "Epoch 2/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.8757 - accuracy: 0.6230 - val_loss: 0.6944 - val_accuracy: 0.6789\n",
      "Epoch 3/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7712 - accuracy: 0.6590 - val_loss: 0.7384 - val_accuracy: 0.6789\n",
      "Epoch 4/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7085 - accuracy: 0.6848 - val_loss: 0.5879 - val_accuracy: 0.7339\n",
      "Epoch 5/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.6455 - accuracy: 0.7301 - val_loss: 0.6370 - val_accuracy: 0.7064\n",
      "Epoch 6/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.6435 - accuracy: 0.7220 - val_loss: 0.6203 - val_accuracy: 0.7385\n",
      "Epoch 7/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.6509 - accuracy: 0.7224 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
      "Epoch 8/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5909 - accuracy: 0.7374 - val_loss: 0.5120 - val_accuracy: 0.7982\n",
      "Epoch 9/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5449 - accuracy: 0.7665 - val_loss: 0.5560 - val_accuracy: 0.7615\n",
      "Epoch 10/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5609 - accuracy: 0.7608 - val_loss: 0.6323 - val_accuracy: 0.7064\n",
      "Epoch 11/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5533 - accuracy: 0.7584 - val_loss: 0.5649 - val_accuracy: 0.7385\n",
      "Epoch 12/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5299 - accuracy: 0.7737 - val_loss: 0.5883 - val_accuracy: 0.7362\n",
      "Epoch 13/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5200 - accuracy: 0.7774 - val_loss: 0.6452 - val_accuracy: 0.6950\n",
      "Epoch 14/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.5057 - accuracy: 0.7749 - val_loss: 0.5634 - val_accuracy: 0.7362\n",
      "Epoch 15/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.4645 - accuracy: 0.7992 - val_loss: 0.5564 - val_accuracy: 0.7294\n",
      "Epoch 16/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.4700 - accuracy: 0.8089 - val_loss: 0.5277 - val_accuracy: 0.7362\n",
      "Epoch 17/120\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.4593 - accuracy: 0.8004 - val_loss: 0.6272 - val_accuracy: 0.6950\n",
      "Epoch 18/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.4751 - accuracy: 0.8004 - val_loss: 0.6070 - val_accuracy: 0.7271\n",
      "Epoch 19/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.4404 - accuracy: 0.8089 - val_loss: 0.5253 - val_accuracy: 0.7477\n",
      "Epoch 20/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.4299 - accuracy: 0.8190 - val_loss: 0.6313 - val_accuracy: 0.7179\n",
      "Epoch 21/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.4014 - accuracy: 0.8283 - val_loss: 0.6778 - val_accuracy: 0.6904\n",
      "Epoch 22/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.4020 - accuracy: 0.8299 - val_loss: 0.5851 - val_accuracy: 0.7431\n",
      "Epoch 23/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.3668 - accuracy: 0.8497 - val_loss: 0.7419 - val_accuracy: 0.7018\n",
      "Epoch 24/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3931 - accuracy: 0.8400 - val_loss: 0.7234 - val_accuracy: 0.7385\n",
      "Epoch 25/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.3499 - accuracy: 0.8594 - val_loss: 0.6855 - val_accuracy: 0.7339\n",
      "Epoch 26/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3110 - accuracy: 0.8675 - val_loss: 0.6650 - val_accuracy: 0.7454\n",
      "Epoch 27/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3385 - accuracy: 0.8586 - val_loss: 0.8104 - val_accuracy: 0.6812\n",
      "Epoch 28/120\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.3273 - accuracy: 0.8663 - val_loss: 0.7898 - val_accuracy: 0.7225\n",
      "Epoch 29/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.3216 - accuracy: 0.8667 - val_loss: 0.7305 - val_accuracy: 0.7546\n",
      "Epoch 30/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3138 - accuracy: 0.8764 - val_loss: 0.6802 - val_accuracy: 0.7317\n",
      "Epoch 31/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.3026 - accuracy: 0.8735 - val_loss: 0.7058 - val_accuracy: 0.7546\n",
      "Epoch 32/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3046 - accuracy: 0.8808 - val_loss: 0.7383 - val_accuracy: 0.7339\n",
      "Epoch 33/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3124 - accuracy: 0.8675 - val_loss: 0.7934 - val_accuracy: 0.7018\n",
      "Epoch 34/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.3000 - accuracy: 0.8796 - val_loss: 0.8732 - val_accuracy: 0.6995\n",
      "Epoch 35/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2844 - accuracy: 0.8824 - val_loss: 0.9212 - val_accuracy: 0.7202\n",
      "Epoch 36/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2500 - accuracy: 0.8958 - val_loss: 0.7406 - val_accuracy: 0.7317\n",
      "Epoch 37/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2558 - accuracy: 0.8909 - val_loss: 0.7931 - val_accuracy: 0.7133\n",
      "Epoch 38/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2189 - accuracy: 0.9071 - val_loss: 1.0881 - val_accuracy: 0.6697\n",
      "Epoch 39/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2417 - accuracy: 0.9018 - val_loss: 0.9006 - val_accuracy: 0.7110\n",
      "Epoch 40/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2542 - accuracy: 0.8998 - val_loss: 0.8391 - val_accuracy: 0.7271\n",
      "Epoch 41/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2612 - accuracy: 0.9002 - val_loss: 0.7760 - val_accuracy: 0.7087\n",
      "Epoch 42/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2163 - accuracy: 0.9176 - val_loss: 1.0381 - val_accuracy: 0.7041\n",
      "Epoch 43/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2209 - accuracy: 0.9123 - val_loss: 1.0812 - val_accuracy: 0.6995\n",
      "Epoch 44/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2099 - accuracy: 0.9192 - val_loss: 1.1007 - val_accuracy: 0.7087\n",
      "Epoch 45/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2275 - accuracy: 0.9119 - val_loss: 1.2187 - val_accuracy: 0.6927\n",
      "Epoch 46/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2063 - accuracy: 0.9232 - val_loss: 1.2424 - val_accuracy: 0.6950\n",
      "Epoch 47/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2544 - accuracy: 0.9030 - val_loss: 1.1273 - val_accuracy: 0.6812\n",
      "Epoch 48/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1711 - accuracy: 0.9325 - val_loss: 1.1560 - val_accuracy: 0.7339\n",
      "Epoch 49/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2765 - accuracy: 0.8982 - val_loss: 0.8977 - val_accuracy: 0.7339\n",
      "Epoch 50/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1987 - accuracy: 0.9236 - val_loss: 1.4114 - val_accuracy: 0.6468\n",
      "Epoch 51/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2349 - accuracy: 0.9051 - val_loss: 1.1267 - val_accuracy: 0.6651\n",
      "Epoch 52/120\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.1829 - accuracy: 0.9301 - val_loss: 1.2999 - val_accuracy: 0.6766\n",
      "Epoch 53/120\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1452 - accuracy: 0.9499 - val_loss: 1.1700 - val_accuracy: 0.7156\n",
      "Epoch 54/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1736 - accuracy: 0.9313 - val_loss: 1.2634 - val_accuracy: 0.7133\n",
      "Epoch 55/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1702 - accuracy: 0.9337 - val_loss: 1.4492 - val_accuracy: 0.6904\n",
      "Epoch 56/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2413 - accuracy: 0.9111 - val_loss: 1.1778 - val_accuracy: 0.6766\n",
      "Epoch 57/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1852 - accuracy: 0.9257 - val_loss: 1.1472 - val_accuracy: 0.7156\n",
      "Epoch 58/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1700 - accuracy: 0.9394 - val_loss: 1.1783 - val_accuracy: 0.7110\n",
      "Epoch 59/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1605 - accuracy: 0.9378 - val_loss: 1.3472 - val_accuracy: 0.6766\n",
      "Epoch 60/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1652 - accuracy: 0.9398 - val_loss: 1.3435 - val_accuracy: 0.6881\n",
      "Epoch 61/120\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1784 - accuracy: 0.9309 - val_loss: 1.4664 - val_accuracy: 0.6583\n",
      "Epoch 62/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.2376 - accuracy: 0.9107 - val_loss: 1.1141 - val_accuracy: 0.7156\n",
      "Epoch 63/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1962 - accuracy: 0.9261 - val_loss: 1.4021 - val_accuracy: 0.7064\n",
      "Epoch 64/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1915 - accuracy: 0.9297 - val_loss: 1.4795 - val_accuracy: 0.6927\n",
      "Epoch 65/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.2022 - accuracy: 0.9265 - val_loss: 1.1008 - val_accuracy: 0.7018\n",
      "Epoch 66/120\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.1381 - accuracy: 0.9442 - val_loss: 1.2048 - val_accuracy: 0.7271\n",
      "Epoch 67/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1606 - accuracy: 0.9406 - val_loss: 1.3170 - val_accuracy: 0.7179\n",
      "Epoch 68/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1595 - accuracy: 0.9402 - val_loss: 1.6178 - val_accuracy: 0.6606\n",
      "Epoch 69/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1492 - accuracy: 0.9430 - val_loss: 1.4875 - val_accuracy: 0.7018\n",
      "Epoch 70/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1614 - accuracy: 0.9410 - val_loss: 1.3329 - val_accuracy: 0.7064\n",
      "Epoch 71/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1638 - accuracy: 0.9426 - val_loss: 1.3885 - val_accuracy: 0.6858\n",
      "Epoch 72/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1969 - accuracy: 0.9301 - val_loss: 1.2931 - val_accuracy: 0.7018\n",
      "Epoch 73/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1747 - accuracy: 0.9329 - val_loss: 1.4357 - val_accuracy: 0.6812\n",
      "Epoch 74/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1394 - accuracy: 0.9475 - val_loss: 1.4430 - val_accuracy: 0.7248\n",
      "Epoch 75/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1206 - accuracy: 0.9511 - val_loss: 1.5052 - val_accuracy: 0.6927\n",
      "Epoch 76/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1763 - accuracy: 0.9341 - val_loss: 1.2111 - val_accuracy: 0.6789\n",
      "Epoch 77/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1373 - accuracy: 0.9483 - val_loss: 1.6953 - val_accuracy: 0.6812\n",
      "Epoch 78/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1052 - accuracy: 0.9572 - val_loss: 1.4815 - val_accuracy: 0.6835\n",
      "Epoch 79/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1759 - accuracy: 0.9325 - val_loss: 1.4908 - val_accuracy: 0.6835\n",
      "Epoch 80/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 1.8065 - val_accuracy: 0.6904\n",
      "Epoch 81/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1340 - accuracy: 0.9475 - val_loss: 1.8225 - val_accuracy: 0.6720\n",
      "Epoch 82/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1727 - accuracy: 0.9410 - val_loss: 1.5707 - val_accuracy: 0.6697\n",
      "Epoch 83/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1576 - accuracy: 0.9410 - val_loss: 1.3255 - val_accuracy: 0.7317\n",
      "Epoch 84/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1443 - accuracy: 0.9479 - val_loss: 1.5823 - val_accuracy: 0.6835\n",
      "Epoch 85/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1408 - accuracy: 0.9499 - val_loss: 1.6696 - val_accuracy: 0.6583\n",
      "Epoch 86/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1552 - accuracy: 0.9434 - val_loss: 1.7568 - val_accuracy: 0.6950\n",
      "Epoch 87/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1789 - accuracy: 0.9329 - val_loss: 1.3553 - val_accuracy: 0.6789\n",
      "Epoch 88/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1690 - accuracy: 0.9386 - val_loss: 1.6344 - val_accuracy: 0.6904\n",
      "Epoch 89/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1511 - accuracy: 0.9446 - val_loss: 1.6469 - val_accuracy: 0.6835\n",
      "Epoch 90/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1503 - accuracy: 0.9479 - val_loss: 1.7491 - val_accuracy: 0.6812\n",
      "Epoch 91/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1652 - accuracy: 0.9406 - val_loss: 1.3968 - val_accuracy: 0.6789\n",
      "Epoch 92/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1197 - accuracy: 0.9572 - val_loss: 1.6385 - val_accuracy: 0.6972\n",
      "Epoch 93/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1481 - accuracy: 0.9511 - val_loss: 1.4281 - val_accuracy: 0.6858\n",
      "Epoch 94/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1224 - accuracy: 0.9568 - val_loss: 1.7449 - val_accuracy: 0.6950\n",
      "Epoch 95/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1530 - accuracy: 0.9515 - val_loss: 1.8726 - val_accuracy: 0.6904\n",
      "Epoch 96/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1648 - accuracy: 0.9418 - val_loss: 1.4424 - val_accuracy: 0.7064\n",
      "Epoch 97/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1141 - accuracy: 0.9620 - val_loss: 1.7565 - val_accuracy: 0.6812\n",
      "Epoch 98/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1296 - accuracy: 0.9535 - val_loss: 1.6001 - val_accuracy: 0.6950\n",
      "Epoch 99/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1128 - accuracy: 0.9600 - val_loss: 1.6932 - val_accuracy: 0.6904\n",
      "Epoch 100/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1109 - accuracy: 0.9628 - val_loss: 1.5995 - val_accuracy: 0.6835\n",
      "Epoch 101/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1471 - accuracy: 0.9523 - val_loss: 1.4337 - val_accuracy: 0.7225\n",
      "Epoch 102/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1290 - accuracy: 0.9515 - val_loss: 1.5478 - val_accuracy: 0.7110\n",
      "Epoch 103/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1070 - accuracy: 0.9568 - val_loss: 1.9882 - val_accuracy: 0.6743\n",
      "Epoch 104/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.0907 - accuracy: 0.9677 - val_loss: 2.0689 - val_accuracy: 0.6950\n",
      "Epoch 105/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1144 - accuracy: 0.9644 - val_loss: 2.1220 - val_accuracy: 0.6835\n",
      "Epoch 106/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1429 - accuracy: 0.9511 - val_loss: 1.9922 - val_accuracy: 0.6835\n",
      "Epoch 107/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.0970 - accuracy: 0.9657 - val_loss: 1.7841 - val_accuracy: 0.6927\n",
      "Epoch 108/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1172 - accuracy: 0.9564 - val_loss: 1.9550 - val_accuracy: 0.6927\n",
      "Epoch 109/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1369 - accuracy: 0.9523 - val_loss: 2.2496 - val_accuracy: 0.6904\n",
      "Epoch 110/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1274 - accuracy: 0.9580 - val_loss: 1.7573 - val_accuracy: 0.6858\n",
      "Epoch 111/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1061 - accuracy: 0.9632 - val_loss: 1.7724 - val_accuracy: 0.6858\n",
      "Epoch 112/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1338 - accuracy: 0.9523 - val_loss: 1.9557 - val_accuracy: 0.6651\n",
      "Epoch 113/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1371 - accuracy: 0.9523 - val_loss: 1.6290 - val_accuracy: 0.7110\n",
      "Epoch 114/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1825 - accuracy: 0.9386 - val_loss: 1.8791 - val_accuracy: 0.7041\n",
      "Epoch 115/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1272 - accuracy: 0.9547 - val_loss: 1.7368 - val_accuracy: 0.6697\n",
      "Epoch 116/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1370 - accuracy: 0.9463 - val_loss: 1.9940 - val_accuracy: 0.6697\n",
      "Epoch 117/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1086 - accuracy: 0.9661 - val_loss: 2.4144 - val_accuracy: 0.6422\n",
      "Epoch 118/120\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.1477 - accuracy: 0.9580 - val_loss: 1.8608 - val_accuracy: 0.6881\n",
      "Epoch 119/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1399 - accuracy: 0.9503 - val_loss: 1.8183 - val_accuracy: 0.6628\n",
      "Epoch 120/120\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.1103 - accuracy: 0.9628 - val_loss: 1.6973 - val_accuracy: 0.6858\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(train_examples, train_labels, epochs=epochs, validation_data=(test_examples, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:13.820673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.2342 - accuracy: 0.4567\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48387, saving model to ./ckpt/reg_lr005/val_acc_0.484.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:15.199807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 2s 20ms/step - loss: 1.2342 - accuracy: 0.4567 - val_loss: 1.0124 - val_accuracy: 0.4839\n",
      "Epoch 2/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.9037 - accuracy: 0.6045\n",
      "Epoch 2: val_accuracy improved from 0.48387 to 0.62097, saving model to ./ckpt/reg_lr005/val_acc_0.621.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.9034 - accuracy: 0.6044 - val_loss: 0.8602 - val_accuracy: 0.6210\n",
      "Epoch 3/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.8050 - accuracy: 0.6438\n",
      "Epoch 3: val_accuracy improved from 0.62097 to 0.63306, saving model to ./ckpt/reg_lr005/val_acc_0.633.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8027 - accuracy: 0.6475 - val_loss: 0.7369 - val_accuracy: 0.6331\n",
      "Epoch 4/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.6947\n",
      "Epoch 4: val_accuracy improved from 0.63306 to 0.69355, saving model to ./ckpt/reg_lr005/val_acc_0.694.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6982 - accuracy: 0.6960 - val_loss: 0.7159 - val_accuracy: 0.6935\n",
      "Epoch 5/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.7128\n",
      "Epoch 5: val_accuracy did not improve from 0.69355\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.6750 - accuracy: 0.7117 - val_loss: 0.7343 - val_accuracy: 0.6613\n",
      "Epoch 6/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.7005\n",
      "Epoch 6: val_accuracy did not improve from 0.69355\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6791 - accuracy: 0.7005 - val_loss: 0.7522 - val_accuracy: 0.6492\n",
      "Epoch 7/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6272 - accuracy: 0.7369\n",
      "Epoch 7: val_accuracy improved from 0.69355 to 0.69758, saving model to ./ckpt/reg_lr005/val_acc_0.698.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6302 - accuracy: 0.7360 - val_loss: 0.7436 - val_accuracy: 0.6976\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.7604\n",
      "Epoch 8: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5884 - accuracy: 0.7598 - val_loss: 0.6903 - val_accuracy: 0.6774\n",
      "Epoch 9/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5585 - accuracy: 0.7601\n",
      "Epoch 9: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5609 - accuracy: 0.7602 - val_loss: 0.7362 - val_accuracy: 0.6653\n",
      "Epoch 10/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.7773\n",
      "Epoch 10: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5225 - accuracy: 0.7773 - val_loss: 0.8389 - val_accuracy: 0.6815\n",
      "Epoch 11/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7975\n",
      "Epoch 11: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4893 - accuracy: 0.7975 - val_loss: 0.6865 - val_accuracy: 0.6694\n",
      "Epoch 12/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.5062 - accuracy: 0.7936\n",
      "Epoch 12: val_accuracy improved from 0.69758 to 0.72581, saving model to ./ckpt/reg_lr005/val_acc_0.726.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5035 - accuracy: 0.7957 - val_loss: 0.6905 - val_accuracy: 0.7258\n",
      "Epoch 13/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.8089\n",
      "Epoch 13: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4464 - accuracy: 0.8083 - val_loss: 0.8952 - val_accuracy: 0.7056\n",
      "Epoch 14/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.7950\n",
      "Epoch 14: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4822 - accuracy: 0.7957 - val_loss: 0.7756 - val_accuracy: 0.6734\n",
      "Epoch 15/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.4261 - accuracy: 0.8191\n",
      "Epoch 15: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4296 - accuracy: 0.8168 - val_loss: 0.8747 - val_accuracy: 0.6694\n",
      "Epoch 16/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4057 - accuracy: 0.8274\n",
      "Epoch 16: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4039 - accuracy: 0.8271 - val_loss: 0.9686 - val_accuracy: 0.6815\n",
      "Epoch 17/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.8514\n",
      "Epoch 17: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.3722 - accuracy: 0.8523 - val_loss: 1.0011 - val_accuracy: 0.6250\n",
      "Epoch 18/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.3779 - accuracy: 0.8368\n",
      "Epoch 18: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.3762 - accuracy: 0.8366 - val_loss: 0.8289 - val_accuracy: 0.6734\n",
      "Epoch 19/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.8637\n",
      "Epoch 19: val_accuracy improved from 0.72581 to 0.72984, saving model to ./ckpt/reg_lr005/val_acc_0.730.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.3399 - accuracy: 0.8639 - val_loss: 0.8458 - val_accuracy: 0.7298\n",
      "Epoch 20/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8617\n",
      "Epoch 20: val_accuracy did not improve from 0.72984\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.3256 - accuracy: 0.8617 - val_loss: 0.8438 - val_accuracy: 0.6935\n",
      "Epoch 21/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.8818\n",
      "Epoch 21: val_accuracy did not improve from 0.72984\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3023 - accuracy: 0.8815 - val_loss: 0.8228 - val_accuracy: 0.6613\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 27s - loss: 1.6320 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:36.629001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.2176 - accuracy: 0.4683\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55242, saving model to ./ckpt/reg_lr005/val_acc_0.552.hdf5\n",
      "70/70 [==============================] - 2s 21ms/step - loss: 1.2176 - accuracy: 0.4683 - val_loss: 0.9884 - val_accuracy: 0.5524\n",
      "Epoch 2/120\n",
      " 5/70 [=>............................] - ETA: 0s - loss: 0.9655 - accuracy: 0.5375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:38.111825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/70 [===========================>..] - ETA: 0s - loss: 0.9007 - accuracy: 0.6063\n",
      "Epoch 2: val_accuracy improved from 0.55242 to 0.66935, saving model to ./ckpt/reg_lr005/val_acc_0.669.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9104 - accuracy: 0.6066 - val_loss: 0.7979 - val_accuracy: 0.6694\n",
      "Epoch 3/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.8081 - accuracy: 0.6413\n",
      "Epoch 3: val_accuracy did not improve from 0.66935\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.8074 - accuracy: 0.6408 - val_loss: 0.8085 - val_accuracy: 0.6492\n",
      "Epoch 4/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7268 - accuracy: 0.6916\n",
      "Epoch 4: val_accuracy improved from 0.66935 to 0.68548, saving model to ./ckpt/reg_lr005/val_acc_0.685.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7319 - accuracy: 0.6906 - val_loss: 0.6880 - val_accuracy: 0.6855\n",
      "Epoch 5/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6469 - accuracy: 0.7224\n",
      "Epoch 5: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.6462 - accuracy: 0.7220 - val_loss: 0.7666 - val_accuracy: 0.6371\n",
      "Epoch 6/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5883 - accuracy: 0.7458\n",
      "Epoch 6: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5871 - accuracy: 0.7467 - val_loss: 0.7660 - val_accuracy: 0.6653\n",
      "Epoch 7/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.5673 - accuracy: 0.7491\n",
      "Epoch 7: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5728 - accuracy: 0.7436 - val_loss: 0.7175 - val_accuracy: 0.6734\n",
      "Epoch 8/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5716 - accuracy: 0.7551\n",
      "Epoch 8: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5794 - accuracy: 0.7512 - val_loss: 0.6992 - val_accuracy: 0.6855\n",
      "Epoch 9/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7764\n",
      "Epoch 9: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.5108 - accuracy: 0.7764 - val_loss: 0.7516 - val_accuracy: 0.6532\n",
      "Epoch 10/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.7721\n",
      "Epoch 10: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.5115 - accuracy: 0.7750 - val_loss: 0.8846 - val_accuracy: 0.6694\n",
      "Epoch 11/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.8019\n",
      "Epoch 11: val_accuracy did not improve from 0.68548\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4790 - accuracy: 0.8029 - val_loss: 0.7690 - val_accuracy: 0.6694\n",
      "Epoch 12/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4071 - accuracy: 0.8344\n",
      "Epoch 12: val_accuracy improved from 0.68548 to 0.70161, saving model to ./ckpt/reg_lr005/val_acc_0.702.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4141 - accuracy: 0.8343 - val_loss: 0.8694 - val_accuracy: 0.7016\n",
      "Epoch 13/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.4040 - accuracy: 0.8277\n",
      "Epoch 13: val_accuracy did not improve from 0.70161\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4059 - accuracy: 0.8258 - val_loss: 0.8902 - val_accuracy: 0.6935\n",
      "Epoch 14/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8460\n",
      "Epoch 14: val_accuracy did not improve from 0.70161\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3860 - accuracy: 0.8460 - val_loss: 0.8390 - val_accuracy: 0.6129\n",
      "Epoch 14: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 28s - loss: 1.6606 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:51.830141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3393 - accuracy: 0.4401\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61694, saving model to ./ckpt/reg_lr005/val_acc_0.617.hdf5\n",
      "70/70 [==============================] - 2s 17ms/step - loss: 1.3393 - accuracy: 0.4401 - val_loss: 1.0064 - val_accuracy: 0.6169\n",
      "Epoch 2/120\n",
      " 5/70 [=>............................] - ETA: 0s - loss: 0.8940 - accuracy: 0.6062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:49:53.050951: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/70 [============================>.] - ETA: 0s - loss: 0.8585 - accuracy: 0.6250\n",
      "Epoch 2: val_accuracy improved from 0.61694 to 0.66129, saving model to ./ckpt/reg_lr005/val_acc_0.661.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.8606 - accuracy: 0.6233 - val_loss: 0.8971 - val_accuracy: 0.6613\n",
      "Epoch 3/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.7585 - accuracy: 0.6632\n",
      "Epoch 3: val_accuracy did not improve from 0.66129\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.7582 - accuracy: 0.6623 - val_loss: 0.9019 - val_accuracy: 0.6210\n",
      "Epoch 4/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6893 - accuracy: 0.6889\n",
      "Epoch 4: val_accuracy improved from 0.66129 to 0.70161, saving model to ./ckpt/reg_lr005/val_acc_0.702.hdf5\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.6892 - accuracy: 0.6888 - val_loss: 0.7687 - val_accuracy: 0.7016\n",
      "Epoch 5/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6291 - accuracy: 0.7151\n",
      "Epoch 5: val_accuracy improved from 0.70161 to 0.71774, saving model to ./ckpt/reg_lr005/val_acc_0.718.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6312 - accuracy: 0.7144 - val_loss: 0.7593 - val_accuracy: 0.7177\n",
      "Epoch 6/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6025 - accuracy: 0.7399\n",
      "Epoch 6: val_accuracy did not improve from 0.71774\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5995 - accuracy: 0.7414 - val_loss: 0.7658 - val_accuracy: 0.7177\n",
      "Epoch 7/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.7355\n",
      "Epoch 7: val_accuracy improved from 0.71774 to 0.72581, saving model to ./ckpt/reg_lr005/val_acc_0.726.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5970 - accuracy: 0.7355 - val_loss: 0.8049 - val_accuracy: 0.7258\n",
      "Epoch 8/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5783 - accuracy: 0.7369\n",
      "Epoch 8: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5764 - accuracy: 0.7382 - val_loss: 0.7485 - val_accuracy: 0.7218\n",
      "Epoch 9/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5401 - accuracy: 0.7612\n",
      "Epoch 9: val_accuracy improved from 0.72581 to 0.74597, saving model to ./ckpt/reg_lr005/val_acc_0.746.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5379 - accuracy: 0.7634 - val_loss: 0.7114 - val_accuracy: 0.7460\n",
      "Epoch 10/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.7609\n",
      "Epoch 10: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5596 - accuracy: 0.7625 - val_loss: 0.8186 - val_accuracy: 0.6895\n",
      "Epoch 11/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7741\n",
      "Epoch 11: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5397 - accuracy: 0.7741 - val_loss: 0.7565 - val_accuracy: 0.7298\n",
      "Epoch 12/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4755 - accuracy: 0.7952\n",
      "Epoch 12: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4812 - accuracy: 0.7939 - val_loss: 0.7861 - val_accuracy: 0.7218\n",
      "Epoch 13/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4989 - accuracy: 0.7826\n",
      "Epoch 13: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.5007 - accuracy: 0.7818 - val_loss: 0.9038 - val_accuracy: 0.7177\n",
      "Epoch 14/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4612 - accuracy: 0.7943\n",
      "Epoch 14: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4643 - accuracy: 0.7912 - val_loss: 0.8105 - val_accuracy: 0.7298\n",
      "Epoch 15/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8102\n",
      "Epoch 15: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4457 - accuracy: 0.8110 - val_loss: 0.9271 - val_accuracy: 0.7097\n",
      "Epoch 16/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4236 - accuracy: 0.8186\n",
      "Epoch 16: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4236 - accuracy: 0.8186 - val_loss: 0.8199 - val_accuracy: 0.7056\n",
      "Epoch 17/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4053 - accuracy: 0.8284\n",
      "Epoch 17: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4025 - accuracy: 0.8307 - val_loss: 0.8308 - val_accuracy: 0.7177\n",
      "Epoch 18/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8320\n",
      "Epoch 18: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4140 - accuracy: 0.8316 - val_loss: 1.1119 - val_accuracy: 0.6976\n",
      "Epoch 19/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4065 - accuracy: 0.8234\n",
      "Epoch 19: val_accuracy did not improve from 0.74597\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4052 - accuracy: 0.8244 - val_loss: 0.8282 - val_accuracy: 0.7379\n",
      "Epoch 19: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 26s - loss: 1.5922 - accuracy: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:12.406655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.4761 - accuracy: 0.3678\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51613, saving model to ./ckpt/reg_lr005/val_acc_0.516.hdf5\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 1.4761 - accuracy: 0.3678 - val_loss: 1.1039 - val_accuracy: 0.5161\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 0.9984 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:13.695563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/70 [===========================>..] - ETA: 0s - loss: 0.9097 - accuracy: 0.5947\n",
      "Epoch 2: val_accuracy improved from 0.51613 to 0.61694, saving model to ./ckpt/reg_lr005/val_acc_0.617.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.9038 - accuracy: 0.5986 - val_loss: 0.8516 - val_accuracy: 0.6169\n",
      "Epoch 3/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.8022 - accuracy: 0.6472\n",
      "Epoch 3: val_accuracy did not improve from 0.61694\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8032 - accuracy: 0.6462 - val_loss: 0.8827 - val_accuracy: 0.5847\n",
      "Epoch 4/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.7564 - accuracy: 0.6719\n",
      "Epoch 4: val_accuracy improved from 0.61694 to 0.67339, saving model to ./ckpt/reg_lr005/val_acc_0.673.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7584 - accuracy: 0.6700 - val_loss: 0.7444 - val_accuracy: 0.6734\n",
      "Epoch 5/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.6974\n",
      "Epoch 5: val_accuracy improved from 0.67339 to 0.69758, saving model to ./ckpt/reg_lr005/val_acc_0.698.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7043 - accuracy: 0.6974 - val_loss: 0.7041 - val_accuracy: 0.6976\n",
      "Epoch 6/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6523 - accuracy: 0.7192\n",
      "Epoch 6: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6568 - accuracy: 0.7167 - val_loss: 0.6923 - val_accuracy: 0.6935\n",
      "Epoch 7/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5974 - accuracy: 0.7407\n",
      "Epoch 7: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5934 - accuracy: 0.7418 - val_loss: 0.7453 - val_accuracy: 0.6895\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5738 - accuracy: 0.7482\n",
      "Epoch 8: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5769 - accuracy: 0.7463 - val_loss: 0.7156 - val_accuracy: 0.6653\n",
      "Epoch 9/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5879 - accuracy: 0.7432\n",
      "Epoch 9: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5897 - accuracy: 0.7427 - val_loss: 0.7462 - val_accuracy: 0.6452\n",
      "Epoch 10/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.7640\n",
      "Epoch 10: val_accuracy did not improve from 0.69758\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5665 - accuracy: 0.7638 - val_loss: 0.6705 - val_accuracy: 0.6935\n",
      "Epoch 11/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.7741\n",
      "Epoch 11: val_accuracy improved from 0.69758 to 0.71774, saving model to ./ckpt/reg_lr005/val_acc_0.718.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5277 - accuracy: 0.7741 - val_loss: 0.6557 - val_accuracy: 0.7177\n",
      "Epoch 12/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.7862\n",
      "Epoch 12: val_accuracy did not improve from 0.71774\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4982 - accuracy: 0.7863 - val_loss: 0.7247 - val_accuracy: 0.7097\n",
      "Epoch 13/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7786\n",
      "Epoch 13: val_accuracy improved from 0.71774 to 0.73387, saving model to ./ckpt/reg_lr005/val_acc_0.734.hdf5\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5108 - accuracy: 0.7786 - val_loss: 0.6670 - val_accuracy: 0.7339\n",
      "Epoch 14/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4544 - accuracy: 0.8120\n",
      "Epoch 14: val_accuracy did not improve from 0.73387\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4564 - accuracy: 0.8114 - val_loss: 0.7130 - val_accuracy: 0.6976\n",
      "Epoch 15/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.7755\n",
      "Epoch 15: val_accuracy did not improve from 0.73387\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5038 - accuracy: 0.7755 - val_loss: 0.8102 - val_accuracy: 0.6694\n",
      "Epoch 16/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4308 - accuracy: 0.8166\n",
      "Epoch 16: val_accuracy did not improve from 0.73387\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4391 - accuracy: 0.8150 - val_loss: 0.8375 - val_accuracy: 0.6613\n",
      "Epoch 17/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.8120\n",
      "Epoch 17: val_accuracy did not improve from 0.73387\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4451 - accuracy: 0.8132 - val_loss: 0.9104 - val_accuracy: 0.6411\n",
      "Epoch 18/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4198 - accuracy: 0.8220\n",
      "Epoch 18: val_accuracy improved from 0.73387 to 0.77419, saving model to ./ckpt/reg_lr005/val_acc_0.774.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4212 - accuracy: 0.8226 - val_loss: 0.6919 - val_accuracy: 0.7742\n",
      "Epoch 19/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4216 - accuracy: 0.8243\n",
      "Epoch 19: val_accuracy did not improve from 0.77419\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4212 - accuracy: 0.8244 - val_loss: 0.7911 - val_accuracy: 0.7137\n",
      "Epoch 20/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4091 - accuracy: 0.8240\n",
      "Epoch 20: val_accuracy did not improve from 0.77419\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4053 - accuracy: 0.8253 - val_loss: 0.8312 - val_accuracy: 0.7177\n",
      "Epoch 21/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8415\n",
      "Epoch 21: val_accuracy did not improve from 0.77419\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.3912 - accuracy: 0.8401 - val_loss: 0.7492 - val_accuracy: 0.6855\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 26s - loss: 1.5910 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:35.561508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.4723 - accuracy: 0.3678\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56855, saving model to ./ckpt/reg_lr005/val_acc_0.569.hdf5\n",
      "70/70 [==============================] - 2s 17ms/step - loss: 1.4723 - accuracy: 0.3678 - val_loss: 1.0074 - val_accuracy: 0.5685\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 1.0323 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:36.738278: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/70 [============================>.] - ETA: 0s - loss: 0.9559 - accuracy: 0.5804\n",
      "Epoch 2: val_accuracy improved from 0.56855 to 0.57258, saving model to ./ckpt/reg_lr005/val_acc_0.573.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9573 - accuracy: 0.5793 - val_loss: 0.8787 - val_accuracy: 0.5726\n",
      "Epoch 3/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.8256 - accuracy: 0.6296\n",
      "Epoch 3: val_accuracy improved from 0.57258 to 0.68952, saving model to ./ckpt/reg_lr005/val_acc_0.690.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.8235 - accuracy: 0.6309 - val_loss: 0.6890 - val_accuracy: 0.6895\n",
      "Epoch 4/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.6716\n",
      "Epoch 4: val_accuracy improved from 0.68952 to 0.71774, saving model to ./ckpt/reg_lr005/val_acc_0.718.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7380 - accuracy: 0.6704 - val_loss: 0.6520 - val_accuracy: 0.7177\n",
      "Epoch 5/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.6852\n",
      "Epoch 5: val_accuracy did not improve from 0.71774\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7279 - accuracy: 0.6852 - val_loss: 0.7703 - val_accuracy: 0.6371\n",
      "Epoch 6/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.7029\n",
      "Epoch 6: val_accuracy did not improve from 0.71774\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6813 - accuracy: 0.7036 - val_loss: 0.6822 - val_accuracy: 0.7177\n",
      "Epoch 7/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.6398 - accuracy: 0.7282\n",
      "Epoch 7: val_accuracy did not improve from 0.71774\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6358 - accuracy: 0.7306 - val_loss: 0.6661 - val_accuracy: 0.7137\n",
      "Epoch 8/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7188\n",
      "Epoch 8: val_accuracy improved from 0.71774 to 0.72581, saving model to ./ckpt/reg_lr005/val_acc_0.726.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6305 - accuracy: 0.7189 - val_loss: 0.6109 - val_accuracy: 0.7258\n",
      "Epoch 9/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6056 - accuracy: 0.7393\n",
      "Epoch 9: val_accuracy did not improve from 0.72581\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.6039 - accuracy: 0.7396 - val_loss: 0.6278 - val_accuracy: 0.7258\n",
      "Epoch 10/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5461 - accuracy: 0.7642\n",
      "Epoch 10: val_accuracy improved from 0.72581 to 0.75000, saving model to ./ckpt/reg_lr005/val_acc_0.750.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5471 - accuracy: 0.7647 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
      "Epoch 11/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5807 - accuracy: 0.7453\n",
      "Epoch 11: val_accuracy did not improve from 0.75000\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5816 - accuracy: 0.7463 - val_loss: 0.6180 - val_accuracy: 0.7298\n",
      "Epoch 12/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5278 - accuracy: 0.7691\n",
      "Epoch 12: val_accuracy improved from 0.75000 to 0.75403, saving model to ./ckpt/reg_lr005/val_acc_0.754.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5260 - accuracy: 0.7714 - val_loss: 0.6262 - val_accuracy: 0.7540\n",
      "Epoch 13/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4970 - accuracy: 0.7849\n",
      "Epoch 13: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4978 - accuracy: 0.7845 - val_loss: 0.6743 - val_accuracy: 0.6653\n",
      "Epoch 14/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4959 - accuracy: 0.7775\n",
      "Epoch 14: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4947 - accuracy: 0.7773 - val_loss: 0.6383 - val_accuracy: 0.7177\n",
      "Epoch 15/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.8039\n",
      "Epoch 15: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4676 - accuracy: 0.8042 - val_loss: 0.6635 - val_accuracy: 0.7218\n",
      "Epoch 16/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8084\n",
      "Epoch 16: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4556 - accuracy: 0.8092 - val_loss: 0.7011 - val_accuracy: 0.6976\n",
      "Epoch 17/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4222 - accuracy: 0.8272\n",
      "Epoch 17: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4239 - accuracy: 0.8262 - val_loss: 0.6996 - val_accuracy: 0.7137\n",
      "Epoch 18/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4129 - accuracy: 0.8335\n",
      "Epoch 18: val_accuracy did not improve from 0.75403\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4147 - accuracy: 0.8303 - val_loss: 0.6728 - val_accuracy: 0.7258\n",
      "Epoch 18: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 25s - loss: 1.6951 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:54.988478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3530 - accuracy: 0.4174\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55061, saving model to ./ckpt/reg_lr005/val_acc_0.551.hdf5\n",
      "70/70 [==============================] - 2s 28ms/step - loss: 1.3530 - accuracy: 0.4174 - val_loss: 0.9829 - val_accuracy: 0.5506\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 0.7124 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:50:56.920529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/70 [===========================>..] - ETA: 0s - loss: 0.8619 - accuracy: 0.6049\n",
      "Epoch 2: val_accuracy improved from 0.55061 to 0.63563, saving model to ./ckpt/reg_lr005/val_acc_0.636.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.8587 - accuracy: 0.6100 - val_loss: 0.7624 - val_accuracy: 0.6356\n",
      "Epoch 3/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.7668 - accuracy: 0.6659\n",
      "Epoch 3: val_accuracy improved from 0.63563 to 0.65992, saving model to ./ckpt/reg_lr005/val_acc_0.660.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7663 - accuracy: 0.6652 - val_loss: 0.7396 - val_accuracy: 0.6599\n",
      "Epoch 4/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6861 - accuracy: 0.6982\n",
      "Epoch 4: val_accuracy improved from 0.65992 to 0.70850, saving model to ./ckpt/reg_lr005/val_acc_0.709.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6853 - accuracy: 0.6993 - val_loss: 0.6721 - val_accuracy: 0.7085\n",
      "Epoch 5/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.7145\n",
      "Epoch 5: val_accuracy did not improve from 0.70850\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6657 - accuracy: 0.7145 - val_loss: 0.6631 - val_accuracy: 0.7004\n",
      "Epoch 6/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.7255\n",
      "Epoch 6: val_accuracy did not improve from 0.70850\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6488 - accuracy: 0.7249 - val_loss: 0.7198 - val_accuracy: 0.6640\n",
      "Epoch 7/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.7154\n",
      "Epoch 7: val_accuracy did not improve from 0.70850\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6268 - accuracy: 0.7154 - val_loss: 0.7392 - val_accuracy: 0.6964\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.7681\n",
      "Epoch 8: val_accuracy did not improve from 0.70850\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.5446 - accuracy: 0.7684 - val_loss: 0.7369 - val_accuracy: 0.6721\n",
      "Epoch 9/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5805 - accuracy: 0.7482\n",
      "Epoch 9: val_accuracy improved from 0.70850 to 0.71255, saving model to ./ckpt/reg_lr005/val_acc_0.713.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5831 - accuracy: 0.7451 - val_loss: 0.6732 - val_accuracy: 0.7126\n",
      "Epoch 10/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.5020 - accuracy: 0.7836\n",
      "Epoch 10: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5020 - accuracy: 0.7850 - val_loss: 0.6358 - val_accuracy: 0.7004\n",
      "Epoch 11/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.8030\n",
      "Epoch 11: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4773 - accuracy: 0.8030 - val_loss: 0.7491 - val_accuracy: 0.6842\n",
      "Epoch 12/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.8030\n",
      "Epoch 12: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4778 - accuracy: 0.8030 - val_loss: 0.7117 - val_accuracy: 0.6721\n",
      "Epoch 13/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7886\n",
      "Epoch 13: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5019 - accuracy: 0.7886 - val_loss: 0.7155 - val_accuracy: 0.6842\n",
      "Epoch 14/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.7980\n",
      "Epoch 14: val_accuracy improved from 0.71255 to 0.72470, saving model to ./ckpt/reg_lr005/val_acc_0.725.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4876 - accuracy: 0.7967 - val_loss: 0.7442 - val_accuracy: 0.7247\n",
      "Epoch 15/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4610 - accuracy: 0.8055\n",
      "Epoch 15: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4642 - accuracy: 0.8025 - val_loss: 0.6957 - val_accuracy: 0.6761\n",
      "Epoch 16/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.8070\n",
      "Epoch 16: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4675 - accuracy: 0.8048 - val_loss: 0.7250 - val_accuracy: 0.6802\n",
      "Epoch 17/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4437 - accuracy: 0.8125\n",
      "Epoch 17: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4474 - accuracy: 0.8115 - val_loss: 0.7911 - val_accuracy: 0.7004\n",
      "Epoch 18/120\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 0.4223 - accuracy: 0.8291\n",
      "Epoch 18: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.4257 - accuracy: 0.8250 - val_loss: 0.8673 - val_accuracy: 0.7045\n",
      "Epoch 19/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8308\n",
      "Epoch 19: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4130 - accuracy: 0.8308 - val_loss: 0.8446 - val_accuracy: 0.7085\n",
      "Epoch 20/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.3777 - accuracy: 0.8460\n",
      "Epoch 20: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.3922 - accuracy: 0.8443 - val_loss: 0.7517 - val_accuracy: 0.7085\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 27s - loss: 1.6985 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:51:17.168265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3285 - accuracy: 0.4215\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57895, saving model to ./ckpt/reg_lr005/val_acc_0.579.hdf5\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 1.3285 - accuracy: 0.4215 - val_loss: 0.9609 - val_accuracy: 0.5789\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:51:18.393965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/70 [============================>.] - ETA: 0s - loss: 0.9226 - accuracy: 0.5951\n",
      "Epoch 2: val_accuracy improved from 0.57895 to 0.60324, saving model to ./ckpt/reg_lr005/val_acc_0.603.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9217 - accuracy: 0.5961 - val_loss: 0.8258 - val_accuracy: 0.6032\n",
      "Epoch 3/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.8070 - accuracy: 0.6420\n",
      "Epoch 3: val_accuracy improved from 0.60324 to 0.66397, saving model to ./ckpt/reg_lr005/val_acc_0.664.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8048 - accuracy: 0.6427 - val_loss: 0.7913 - val_accuracy: 0.6640\n",
      "Epoch 4/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7373 - accuracy: 0.6834\n",
      "Epoch 4: val_accuracy improved from 0.66397 to 0.68016, saving model to ./ckpt/reg_lr005/val_acc_0.680.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7372 - accuracy: 0.6827 - val_loss: 0.7424 - val_accuracy: 0.6802\n",
      "Epoch 5/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7073 - accuracy: 0.6762\n",
      "Epoch 5: val_accuracy improved from 0.68016 to 0.72470, saving model to ./ckpt/reg_lr005/val_acc_0.725.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7081 - accuracy: 0.6755 - val_loss: 0.6114 - val_accuracy: 0.7247\n",
      "Epoch 6/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6942 - accuracy: 0.7008\n",
      "Epoch 6: val_accuracy improved from 0.72470 to 0.79757, saving model to ./ckpt/reg_lr005/val_acc_0.798.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6887 - accuracy: 0.7033 - val_loss: 0.5092 - val_accuracy: 0.7976\n",
      "Epoch 7/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6037 - accuracy: 0.7330\n",
      "Epoch 7: val_accuracy did not improve from 0.79757\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6078 - accuracy: 0.7329 - val_loss: 0.5744 - val_accuracy: 0.7449\n",
      "Epoch 8/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.7284\n",
      "Epoch 8: val_accuracy improved from 0.79757 to 0.80567, saving model to ./ckpt/reg_lr005/val_acc_0.806.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6316 - accuracy: 0.7271 - val_loss: 0.5266 - val_accuracy: 0.8057\n",
      "Epoch 9/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5709 - accuracy: 0.7550\n",
      "Epoch 9: val_accuracy improved from 0.80567 to 0.81377, saving model to ./ckpt/reg_lr005/val_acc_0.814.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5723 - accuracy: 0.7545 - val_loss: 0.4989 - val_accuracy: 0.8138\n",
      "Epoch 10/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5636 - accuracy: 0.7527\n",
      "Epoch 10: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5660 - accuracy: 0.7518 - val_loss: 0.4760 - val_accuracy: 0.7854\n",
      "Epoch 11/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.7668\n",
      "Epoch 11: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5513 - accuracy: 0.7657 - val_loss: 0.5228 - val_accuracy: 0.7652\n",
      "Epoch 12/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5271 - accuracy: 0.7799\n",
      "Epoch 12: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5281 - accuracy: 0.7792 - val_loss: 0.4888 - val_accuracy: 0.7976\n",
      "Epoch 13/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5070 - accuracy: 0.7812\n",
      "Epoch 13: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5088 - accuracy: 0.7801 - val_loss: 0.5713 - val_accuracy: 0.7530\n",
      "Epoch 14/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.7844\n",
      "Epoch 14: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5105 - accuracy: 0.7841 - val_loss: 0.4883 - val_accuracy: 0.8138\n",
      "Epoch 15/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4863 - accuracy: 0.7924\n",
      "Epoch 15: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4844 - accuracy: 0.7931 - val_loss: 0.4879 - val_accuracy: 0.7935\n",
      "Epoch 16/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8066\n",
      "Epoch 16: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4828 - accuracy: 0.8066 - val_loss: 0.5845 - val_accuracy: 0.7449\n",
      "Epoch 17/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4419 - accuracy: 0.8074\n",
      "Epoch 17: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4455 - accuracy: 0.8057 - val_loss: 0.5288 - val_accuracy: 0.7895\n",
      "Epoch 18/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4549 - accuracy: 0.8003\n",
      "Epoch 18: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4571 - accuracy: 0.7989 - val_loss: 0.5098 - val_accuracy: 0.7773\n",
      "Epoch 19/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.8093\n",
      "Epoch 19: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4541 - accuracy: 0.8083 - val_loss: 0.6909 - val_accuracy: 0.6761\n",
      "Epoch 20/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.8062\n",
      "Epoch 20: val_accuracy did not improve from 0.81377\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4626 - accuracy: 0.8066 - val_loss: 0.5786 - val_accuracy: 0.7814\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:51:39.046934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3623 - accuracy: 0.3927\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54656, saving model to ./ckpt/reg_lr005/val_acc_0.547.hdf5\n",
      "70/70 [==============================] - 2s 17ms/step - loss: 1.3623 - accuracy: 0.3927 - val_loss: 0.9722 - val_accuracy: 0.5466\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 0.9956 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:51:40.299676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/70 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.5786\n",
      "Epoch 2: val_accuracy improved from 0.54656 to 0.59109, saving model to ./ckpt/reg_lr005/val_acc_0.591.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9754 - accuracy: 0.5781 - val_loss: 0.8522 - val_accuracy: 0.5911\n",
      "Epoch 3/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.8414 - accuracy: 0.6264\n",
      "Epoch 3: val_accuracy improved from 0.59109 to 0.63968, saving model to ./ckpt/reg_lr005/val_acc_0.640.hdf5\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.8416 - accuracy: 0.6275 - val_loss: 0.8207 - val_accuracy: 0.6397\n",
      "Epoch 4/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.7807 - accuracy: 0.6625\n",
      "Epoch 4: val_accuracy improved from 0.63968 to 0.74899, saving model to ./ckpt/reg_lr005/val_acc_0.749.hdf5\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.7807 - accuracy: 0.6625 - val_loss: 0.6387 - val_accuracy: 0.7490\n",
      "Epoch 5/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7516 - accuracy: 0.6716\n",
      "Epoch 5: val_accuracy did not improve from 0.74899\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7513 - accuracy: 0.6706 - val_loss: 0.5946 - val_accuracy: 0.7368\n",
      "Epoch 6/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6852 - accuracy: 0.7111\n",
      "Epoch 6: val_accuracy did not improve from 0.74899\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6855 - accuracy: 0.7096 - val_loss: 0.6602 - val_accuracy: 0.6599\n",
      "Epoch 7/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6515 - accuracy: 0.7146\n",
      "Epoch 7: val_accuracy did not improve from 0.74899\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6539 - accuracy: 0.7132 - val_loss: 0.7093 - val_accuracy: 0.6761\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6369 - accuracy: 0.7382\n",
      "Epoch 8: val_accuracy did not improve from 0.74899\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.6376 - accuracy: 0.7374 - val_loss: 0.6388 - val_accuracy: 0.7287\n",
      "Epoch 9/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6314 - accuracy: 0.7301\n",
      "Epoch 9: val_accuracy did not improve from 0.74899\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.6345 - accuracy: 0.7294 - val_loss: 0.6668 - val_accuracy: 0.6761\n",
      "Epoch 10/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5994 - accuracy: 0.7459\n",
      "Epoch 10: val_accuracy improved from 0.74899 to 0.77328, saving model to ./ckpt/reg_lr005/val_acc_0.773.hdf5\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.6008 - accuracy: 0.7460 - val_loss: 0.5631 - val_accuracy: 0.7733\n",
      "Epoch 11/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.7536\n",
      "Epoch 11: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5916 - accuracy: 0.7531 - val_loss: 0.5828 - val_accuracy: 0.7328\n",
      "Epoch 12/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7567\n",
      "Epoch 12: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.5669 - accuracy: 0.7567 - val_loss: 0.5560 - val_accuracy: 0.7409\n",
      "Epoch 13/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.7509\n",
      "Epoch 13: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5710 - accuracy: 0.7504 - val_loss: 0.7679 - val_accuracy: 0.7004\n",
      "Epoch 14/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.7794\n",
      "Epoch 14: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5394 - accuracy: 0.7792 - val_loss: 0.6811 - val_accuracy: 0.6761\n",
      "Epoch 15/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7686\n",
      "Epoch 15: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5348 - accuracy: 0.7697 - val_loss: 0.6579 - val_accuracy: 0.7004\n",
      "Epoch 16/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.7717\n",
      "Epoch 16: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5243 - accuracy: 0.7711 - val_loss: 0.6476 - val_accuracy: 0.6923\n",
      "Epoch 17/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.7853\n",
      "Epoch 17: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5264 - accuracy: 0.7859 - val_loss: 0.7001 - val_accuracy: 0.6559\n",
      "Epoch 18/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5133 - accuracy: 0.7826\n",
      "Epoch 18: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5117 - accuracy: 0.7828 - val_loss: 0.5926 - val_accuracy: 0.7328\n",
      "Epoch 19/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.8038\n",
      "Epoch 19: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4899 - accuracy: 0.8048 - val_loss: 0.6159 - val_accuracy: 0.7449\n",
      "Epoch 20/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8143\n",
      "Epoch 20: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4623 - accuracy: 0.8146 - val_loss: 0.6045 - val_accuracy: 0.7166\n",
      "Epoch 21/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4567 - accuracy: 0.8102\n",
      "Epoch 21: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4592 - accuracy: 0.8097 - val_loss: 0.5861 - val_accuracy: 0.7652\n",
      "Epoch 22/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8030\n",
      "Epoch 22: val_accuracy did not improve from 0.77328\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8030 - val_loss: 0.6033 - val_accuracy: 0.7247\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/120\n",
      " 1/70 [..............................] - ETA: 27s - loss: 1.6464 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:52:02.744315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3127 - accuracy: 0.4255\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56680, saving model to ./ckpt/reg_lr005/val_acc_0.567.hdf5\n",
      "70/70 [==============================] - 2s 18ms/step - loss: 1.3127 - accuracy: 0.4255 - val_loss: 0.9486 - val_accuracy: 0.5668\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 1.2861 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:52:03.992501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/70 [============================>.] - ETA: 0s - loss: 0.9276 - accuracy: 0.5901\n",
      "Epoch 2: val_accuracy improved from 0.56680 to 0.69231, saving model to ./ckpt/reg_lr005/val_acc_0.692.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9267 - accuracy: 0.5916 - val_loss: 0.7840 - val_accuracy: 0.6923\n",
      "Epoch 3/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.7983 - accuracy: 0.6436\n",
      "Epoch 3: val_accuracy did not improve from 0.69231\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7983 - accuracy: 0.6436 - val_loss: 0.7059 - val_accuracy: 0.6518\n",
      "Epoch 4/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.7039 - accuracy: 0.7006\n",
      "Epoch 4: val_accuracy improved from 0.69231 to 0.71255, saving model to ./ckpt/reg_lr005/val_acc_0.713.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7043 - accuracy: 0.6975 - val_loss: 0.6826 - val_accuracy: 0.7126\n",
      "Epoch 5/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6743 - accuracy: 0.7011\n",
      "Epoch 5: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6739 - accuracy: 0.7020 - val_loss: 0.7062 - val_accuracy: 0.6761\n",
      "Epoch 6/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6381 - accuracy: 0.7169\n",
      "Epoch 6: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6382 - accuracy: 0.7159 - val_loss: 0.6747 - val_accuracy: 0.6478\n",
      "Epoch 7/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.7382\n",
      "Epoch 7: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6035 - accuracy: 0.7379 - val_loss: 0.6702 - val_accuracy: 0.6802\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5683 - accuracy: 0.7586\n",
      "Epoch 8: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5700 - accuracy: 0.7576 - val_loss: 0.7299 - val_accuracy: 0.6680\n",
      "Epoch 9/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5641 - accuracy: 0.7659\n",
      "Epoch 9: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5633 - accuracy: 0.7662 - val_loss: 0.7065 - val_accuracy: 0.6518\n",
      "Epoch 10/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.7690\n",
      "Epoch 10: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5446 - accuracy: 0.7680 - val_loss: 0.6827 - val_accuracy: 0.7126\n",
      "Epoch 11/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.7772\n",
      "Epoch 11: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5432 - accuracy: 0.7765 - val_loss: 0.6741 - val_accuracy: 0.6761\n",
      "Epoch 12/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4984 - accuracy: 0.7927\n",
      "Epoch 12: val_accuracy did not improve from 0.71255\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5027 - accuracy: 0.7895 - val_loss: 0.6836 - val_accuracy: 0.6964\n",
      "Epoch 13/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.4954 - accuracy: 0.7934\n",
      "Epoch 13: val_accuracy improved from 0.71255 to 0.72470, saving model to ./ckpt/reg_lr005/val_acc_0.725.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4971 - accuracy: 0.7940 - val_loss: 0.6552 - val_accuracy: 0.7247\n",
      "Epoch 14/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.7895\n",
      "Epoch 14: val_accuracy did not improve from 0.72470\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4977 - accuracy: 0.7868 - val_loss: 0.7531 - val_accuracy: 0.6640\n",
      "Epoch 15/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8107\n",
      "Epoch 15: val_accuracy improved from 0.72470 to 0.72874, saving model to ./ckpt/reg_lr005/val_acc_0.729.hdf5\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4553 - accuracy: 0.8088 - val_loss: 0.6653 - val_accuracy: 0.7287\n",
      "Epoch 16/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8125\n",
      "Epoch 16: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4414 - accuracy: 0.8119 - val_loss: 0.7861 - val_accuracy: 0.6761\n",
      "Epoch 17/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8263\n",
      "Epoch 17: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4346 - accuracy: 0.8263 - val_loss: 0.8336 - val_accuracy: 0.6842\n",
      "Epoch 18/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.8143\n",
      "Epoch 18: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4338 - accuracy: 0.8151 - val_loss: 0.8282 - val_accuracy: 0.6761\n",
      "Epoch 19/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8166\n",
      "Epoch 19: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4282 - accuracy: 0.8178 - val_loss: 0.7218 - val_accuracy: 0.6761\n",
      "Epoch 20/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4134 - accuracy: 0.8265\n",
      "Epoch 20: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4139 - accuracy: 0.8259 - val_loss: 0.7445 - val_accuracy: 0.7085\n",
      "Epoch 21/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8324\n",
      "Epoch 21: val_accuracy did not improve from 0.72874\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.3919 - accuracy: 0.8303 - val_loss: 0.8275 - val_accuracy: 0.6478\n",
      "Epoch 22/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4123 - accuracy: 0.8315\n",
      "Epoch 22: val_accuracy improved from 0.72874 to 0.73279, saving model to ./ckpt/reg_lr005/val_acc_0.733.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4111 - accuracy: 0.8317 - val_loss: 0.8058 - val_accuracy: 0.7328\n",
      "Epoch 23/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8254\n",
      "Epoch 23: val_accuracy did not improve from 0.73279\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4039 - accuracy: 0.8254 - val_loss: 0.8191 - val_accuracy: 0.6964\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:52:28.489187: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.3604 - accuracy: 0.4129\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57085, saving model to ./ckpt/reg_lr005/val_acc_0.571.hdf5\n",
      "70/70 [==============================] - 3s 27ms/step - loss: 1.3604 - accuracy: 0.4129 - val_loss: 0.9625 - val_accuracy: 0.5709\n",
      "Epoch 2/120\n",
      " 1/70 [..............................] - ETA: 1s - loss: 0.9639 - accuracy: 0.6250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:52:30.531973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/70 [============================>.] - ETA: 0s - loss: 0.9669 - accuracy: 0.5747\n",
      "Epoch 2: val_accuracy improved from 0.57085 to 0.57895, saving model to ./ckpt/reg_lr005/val_acc_0.579.hdf5\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.9661 - accuracy: 0.5754 - val_loss: 0.9099 - val_accuracy: 0.5789\n",
      "Epoch 3/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.8271 - accuracy: 0.6368\n",
      "Epoch 3: val_accuracy improved from 0.57895 to 0.63563, saving model to ./ckpt/reg_lr005/val_acc_0.636.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.8264 - accuracy: 0.6378 - val_loss: 0.8250 - val_accuracy: 0.6356\n",
      "Epoch 4/120\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.7510 - accuracy: 0.6625\n",
      "Epoch 4: val_accuracy improved from 0.63563 to 0.74089, saving model to ./ckpt/reg_lr005/val_acc_0.741.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.7510 - accuracy: 0.6625 - val_loss: 0.6629 - val_accuracy: 0.7409\n",
      "Epoch 5/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.6999\n",
      "Epoch 5: val_accuracy did not improve from 0.74089\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6797 - accuracy: 0.6984 - val_loss: 0.7381 - val_accuracy: 0.6437\n",
      "Epoch 6/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.7397 - accuracy: 0.6839\n",
      "Epoch 6: val_accuracy did not improve from 0.74089\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.7406 - accuracy: 0.6827 - val_loss: 0.6462 - val_accuracy: 0.7085\n",
      "Epoch 7/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.7083\n",
      "Epoch 7: val_accuracy did not improve from 0.74089\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6554 - accuracy: 0.7078 - val_loss: 0.8092 - val_accuracy: 0.6397\n",
      "Epoch 8/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.6155 - accuracy: 0.7292\n",
      "Epoch 8: val_accuracy did not improve from 0.74089\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.6149 - accuracy: 0.7294 - val_loss: 0.6051 - val_accuracy: 0.7368\n",
      "Epoch 9/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.6099 - accuracy: 0.7374\n",
      "Epoch 9: val_accuracy improved from 0.74089 to 0.76923, saving model to ./ckpt/reg_lr005/val_acc_0.769.hdf5\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.6055 - accuracy: 0.7410 - val_loss: 0.5623 - val_accuracy: 0.7692\n",
      "Epoch 10/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.5945 - accuracy: 0.7463\n",
      "Epoch 10: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5927 - accuracy: 0.7478 - val_loss: 0.5950 - val_accuracy: 0.7287\n",
      "Epoch 11/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5312 - accuracy: 0.7738\n",
      "Epoch 11: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5343 - accuracy: 0.7729 - val_loss: 0.5756 - val_accuracy: 0.7611\n",
      "Epoch 12/120\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 0.5269 - accuracy: 0.7868\n",
      "Epoch 12: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5329 - accuracy: 0.7832 - val_loss: 0.5947 - val_accuracy: 0.7692\n",
      "Epoch 13/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5236 - accuracy: 0.7826\n",
      "Epoch 13: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5291 - accuracy: 0.7805 - val_loss: 0.6281 - val_accuracy: 0.7045\n",
      "Epoch 14/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.7822\n",
      "Epoch 14: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5352 - accuracy: 0.7814 - val_loss: 0.5665 - val_accuracy: 0.7530\n",
      "Epoch 15/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.7948\n",
      "Epoch 15: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4959 - accuracy: 0.7953 - val_loss: 0.5966 - val_accuracy: 0.7045\n",
      "Epoch 16/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.7985\n",
      "Epoch 16: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4771 - accuracy: 0.7980 - val_loss: 0.9132 - val_accuracy: 0.6964\n",
      "Epoch 17/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.7740\n",
      "Epoch 17: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5176 - accuracy: 0.7747 - val_loss: 0.6573 - val_accuracy: 0.7368\n",
      "Epoch 18/120\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.8143\n",
      "Epoch 18: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4500 - accuracy: 0.8142 - val_loss: 0.8071 - val_accuracy: 0.6194\n",
      "Epoch 19/120\n",
      "68/70 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.8208\n",
      "Epoch 19: val_accuracy did not improve from 0.76923\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4484 - accuracy: 0.8200 - val_loss: 0.5980 - val_accuracy: 0.7652\n",
      "Epoch 19: early stopping\n",
      "Finish 10-fold cross validation\n",
      "Best performing model has 0.8138 validation accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# modify to save ckpt for each test\n",
    "ckpt = os.path.join(ckpt_path, \"val_acc_{val_accuracy:.3f}.hdf5\")\n",
    "\n",
    "# training params\n",
    "epochs = epochs\n",
    "num_classes = num_classes\n",
    "lr = lr\n",
    "\n",
    "# the k for k fold CV\n",
    "n_split = 10\n",
    "\n",
    "# for recording best performance\n",
    "max_acc = 0\n",
    "best_history = None\n",
    "\n",
    "'''\n",
    "k-fold cross validation\n",
    "Save the best model using validation accuracy as metric\n",
    "Print the global best performace when finished\n",
    "'''\n",
    "for train_index, test_index in KFold(n_split).split(train_examples):\n",
    "\n",
    "    x_train, x_vad = train_examples[train_index], train_examples[test_index]\n",
    "    y_train, y_vad = train_labels[train_index], train_labels[test_index]\n",
    "\n",
    "    model=create_model(num_classes, lr)\n",
    "  \n",
    "    # callbacks\n",
    "    checkpoint_filepath = ckpt\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "    )\n",
    "\n",
    "    # Model weights are saved at the end of every epoch, if it's the best seen so far.\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_vad, y_vad),\n",
    "                        callbacks=[model_checkpoint_callback, early_stopping_callback])\n",
    "\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    \n",
    "    if val_acc > max_acc:\n",
    "        max_acc = val_acc\n",
    "        best_history = history\n",
    "        # print('Best acc so far. Saving params...\\n')\n",
    "\n",
    "print('Finish {}-fold cross validation'.format(n_split))\n",
    "print('Best performing model has {:.4f} validation accuracy'.format(max_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = best_history\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# because of early stopping, can't just use \"epochs\"\n",
    "epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/14 [==============>...............] - ETA: 0s - loss: 0.4102 - accuracy: 0.8259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 22:55:50.271133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4835 - accuracy: 0.8096\n",
      "\n",
      "evaluate on test set:\n",
      "loss = 0.48346\tacc = 80.963%\n"
     ]
    }
   ],
   "source": [
    "model = create_model(num_classes=num_classes)\n",
    "model.load_weights(os.path.join(ckpt_path, \"val_acc_0.754.hdf5\"))\n",
    "\n",
    "loss, acc = model.evaluate(test_examples, test_labels)\n",
    "\n",
    "print('\\nevaluate on test set:\\nloss = {:.5f}\\tacc = {:.3f}%'.format(loss, acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29cc21816e506614f017a9125cfdb1f5dc655865e499c52ef5f5406a40d25695"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
